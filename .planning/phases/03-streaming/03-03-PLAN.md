---
phase: 03-streaming
plan: 03
type: execute
wave: 3
depends_on: ["03-02"]
files_modified: [src/lib/debateEngine.ts, src/components/DebateDashboard.tsx]
autonomous: false

must_haves:
  truths:
    - "Debate engine triggers streaming AI generation for each speaker"
    - "Streaming content flows from engine through store to UI"
    - "User sees real-time streaming during actual debate execution"
  artifacts:
    - path: "src/lib/debateEngine.ts"
      provides: "Streaming-enabled debate orchestration"
      contains: "streamSpeakerContent"
    - path: "src/components/DebateDashboard.tsx"
      provides: "Streaming debate coordination"
  key_links:
    - from: "src/lib/debateEngine.ts"
      to: "src/lib/aiAgents.ts"
      via: "streamSpeakerContent call"
      pattern: "await streamSpeakerContent"
    - from: "src/lib/debateEngine.ts"
      to: "src/store/debateStore.ts"
      via: "startStreamingEntry action"
      pattern: "startStreamingEntry"
---

<objective>
Integrate streaming AI generation into the debate engine and wire end-to-end flow.

Purpose: Complete the streaming pipeline from AI generation through store to UI display
Output: Fully functional streaming debate experience
</objective>

<execution_context>
@~/.config/opencode/get-shit-done/workflows/execute-plan.md
@~/.config/opencode/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-streaming/03-RESEARCH.md

# Dependencies
@.planning/phases/03-streaming/03-01-SUMMARY.md
@.planning/phases/03-streaming/03-02-SUMMARY.md

# Files to modify
@src/lib/debateEngine.ts
@src/components/DebateDashboard.tsx
</context>

<tasks>

<task type="auto">
  <name>Task 1: Update debate engine for streaming</name>
  <files>src/lib/debateEngine.ts</files>
  <action>
Modify debate engine to use streaming AI generation:

1. Import `streamSpeakerContent` from aiAgents (alongside existing imports)
2. Find where `generateSpeakerContent` is currently called (likely in speaker turn handling)
3. Replace with streaming approach:
   ```typescript
   // Get stream generator
   const streamGen = streamSpeakerContent(role, motion, previousStatements);
   
   // Pass to store to start streaming entry
   const store = useDebateStore.getState();
   store.startStreamingEntry(currentSpeaker, streamGen);
   ```

4. Remove any await on content generation - streaming is fire-and-forget from engine perspective
5. Keep existing timer logic and turn management unchanged
6. Add error handling: if streaming fails, use `cancelStreamingEntry()` and show error in UI

Key architectural change: Engine no longer waits for full AI response before proceeding. It starts the stream, then continues with timer/turn logic.

Why async fire-and-forget: Streaming happens in background via hooks, engine just initiates it and moves on to timer management.
  </action>
  <verify>
1. Check streamSpeakerContent import: `grep "import.*streamSpeakerContent" src/lib/debateEngine.ts`
2. Check store integration: `grep "startStreamingEntry" src/lib/debateEngine.ts`
3. Verify no blocking awaits on generation: `grep -v "await.*generateText\|await.*generateSpeakerContent" src/lib/debateEngine.ts | grep "streamSpeakerContent" || echo "Correctly non-blocking"`
4. Verify TypeScript compiles: `npm run build`
  </verify>
  <done>
- debateEngine.ts uses streamSpeakerContent for AI generation
- Calls startStreamingEntry on store to initiate streaming
- No blocking awaits on content generation
- Error handling with cancelStreamingEntry on failures
- TypeScript compiles without errors
  </done>
</task>

<task type="auto">
  <name>Task 2: Wire debate start to streaming flow</name>
  <files>src/components/DebateDashboard.tsx</files>
  <action>
Ensure DebateDashboard properly initiates streaming debates:

1. Verify `startDebate` action is called when user clicks "Start Debate" button
2. After debate starts, the engine should automatically trigger first speaker (PM) streaming
3. No changes needed to button click handlers - streaming happens automatically via engine

Verification checks to add:
- Console.log when streaming starts (temporary debug log)
- Check that streamingEntry appears in React DevTools when debate starts

This task is primarily verification that existing wiring works with new streaming architecture. Only modify if integration issues are discovered during testing.

Why minimal changes: Dashboard already orchestrates debate start, engine handles speaker management, streaming is transparent to dashboard.
  </action>
  <verify>
1. Start dev server: `npm run dev`
2. Open browser to localhost:5173
3. Enter a valid motion
4. Click "Start Debate" 
5. Check console for streaming initialization logs
6. Verify no TypeScript/runtime errors in console
7. Check React DevTools: streamingEntry should appear in store state
  </verify>
  <done>
- DebateDashboard starts debate with streaming flow
- Streaming entry appears in store when debate starts
- No console errors during debate initialization
- TypeScript compiles without errors
  </done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>
  Complete streaming pipeline: AI agents → debate engine → store → UI components
  
  Tasks completed:
  - Debate engine integrated with streamSpeakerContent
  - Dashboard wired to initiate streaming debates
  - End-to-end flow from user action to streaming display
  </what-built>
  
  <how-to-verify>
  Test the complete streaming experience:
  
  1. **Start development server:**
     ```bash
     npm run dev
     ```
  
  2. **Open browser to http://localhost:5173**
  
  3. **Test streaming flow:**
     - Enter motion: "This House believes that AI will improve education"
     - Click "Start Debate"
     - Observe PM's speech streaming incrementally in transcript panel
     - Verify text appears word-by-word or chunk-by-chunk (not all at once)
     - Check that pulsing border animation shows during streaming
     - Verify animation stops when speech completes
     - Confirm completed speech appears as normal SpeakerCard
  
  4. **Check for issues:**
     - No console errors during streaming
     - Text accumulates smoothly without jank
     - Timer continues running during streaming
     - Auto-scroll keeps streaming entry visible
     - Streaming entry finalizes to transcript properly
  
  5. **Test error cases:**
     - If streaming fails, check that error is handled gracefully
     - Verify cancelStreamingEntry cleans up state
  
  **Expected behavior:**
  - ✅ Text streams in real-time as AI generates content
  - ✅ Smooth visual updates without excessive re-renders
  - ✅ Pulsing animation during streaming, removed on completion
  - ✅ Streaming entry converts to permanent transcript entry
  - ✅ No memory leaks or console errors
  
  **Known limitations at this stage:**
  - ⚠️  No TTS audio yet (Phase 3 Plan 03 focuses on text streaming only)
  - ⚠️  Using OpenAI model config (DeepSeek API integration pending user API key setup)
  </how-to-verify>
  
  <resume-signal>
  Type "approved" if streaming works as expected, or describe any issues observed
  </resume-signal>
</task>

</tasks>

<verification>
After completing all tasks:

1. **TypeScript compilation:** `npm run build` succeeds
2. **Engine integration:** debateEngine uses streamSpeakerContent
3. **Store wiring:** Engine calls startStreamingEntry
4. **Dev server:** `npm run dev` runs without errors
5. **Manual testing:** Streaming visible in browser
</verification>

<success_criteria>
- Debate engine initiates streaming for each speaker turn
- Streaming content flows from AI agents → store → UI
- User sees real-time incremental text display during debates
- Streaming entries finalize to permanent transcript
- No console errors or memory leaks
- End-to-end streaming pipeline complete
</success_criteria>

<output>
After completion, create `.planning/phases/03-streaming/03-03-SUMMARY.md`
</output>
