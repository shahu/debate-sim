---
phase: 04-audio-enhancement
plan: 03
type: execute
wave: 3
depends_on: ["04-01", "04-02"]
files_modified:
  - src/hooks/useTTS.ts
  - src/components/StreamingTranscriptEntry.tsx
  - src/components/DebateDashboard.tsx
autonomous: true

must_haves:
  truths:
    - "Each speaker role uses a distinct voice when TTS is enabled"
    - "TTS audio queues text as it streams from the debate AI"
    - "Audio can be globally enabled/disabled via audio store"
    - "TTS audio elements connected to shared GainNode for global volume control"
  artifacts:
    - path: "src/hooks/useTTS.ts"
      provides: "Enhanced TTS hook with role-based voice support"
      exports: ["useStreamingTTS", "speakText"]
      updates: "Added speaker parameter, integrated with audio store and shared audio context"
    - path: "src/components/StreamingTranscriptEntry.tsx"
      provides: "Streaming transcript with integrated TTS playback"
      updates: "Added TTS integration, voice selection per speaker role, audio elements connected to shared GainNode"
    - path: "src/components/DebateDashboard.tsx"
      provides: "Dashboard with audio controls and enabled TTS"
      updates: "Added AudioControls component, passed speaker role to streaming"
  key_links:
    - from: "src/hooks/useTTS.ts"
      to: "src/store/audioStore.ts"
      via: "useAudioStore import for isEnabled check"
      pattern: "from.*audioStore"
    - from: "src/hooks/useTTS.ts"
      to: "src/lib/voiceRegistry.ts"
      via: "getVoiceIdForRole import for voice selection"
      pattern: "from.*voiceRegistry"
    - from: "src/hooks/useTTS.ts"
      to: "src/components/AudioControls.tsx"
      via: "applyGlobalVolume import to connect audio elements to shared GainNode"
      pattern: "from.*AudioControls"
    - from: "src/components/StreamingTranscriptEntry.tsx"
      to: "src/hooks/useTTS.ts"
      via: "useStreamingTTS import for streaming TTS"
      pattern: "from.*useTTS"
    - from: "src/components/DebateDashboard.tsx"
      to: "src/components/AudioControls.tsx"
      via: "AudioControls import"
      pattern: "from.*AudioControls"
---

<objective>
Integrate TTS with streaming debate text using role-based voice selection, connect audio controls to dashboard, and enable real-time audio playback as content streams.

Purpose: Enable users to hear the debate with distinct voices for each speaker role, with global audio controls to adjust playback.

Output: Enhanced useStreamingTTS hook with voice support, StreamingTranscriptEntry with TTS integration, DebateDashboard with AudioControls component.
</objective>

<execution_context>
@~/.config/opencode/get-shit-done/workflows/execute-plan.md
@~/.config/opencode/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-audio-enhancement/04-RESEARCH.md
@.planning/phases/04-audio-enhancement/04-01-PLAN.md
@.planning/phases/04-audio-enhancement/04-02-PLAN.md

# Existing codebase
@src/hooks/useTTS.ts
@src/components/StreamingTranscriptEntry.tsx
@src/components/DebateDashboard.tsx
@src/lib/voiceRegistry.ts
@src/store/audioStore.ts
@src/store/debateStore.ts
@src/types/debate.ts

# Prior phase summaries
@.planning/phases/03-streaming/03-02-SUMMARY.md
@.planning/phases/03-streaming/03-03-SUMMARY.md
@.planning/phases/04-audio-enhancement/04-01-SUMMARY.md
@.planning/phases/04-audio-enhancement/04-02-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Enhance useStreamingTTS hook with role-based voice, audio store, and shared audio context integration</name>
  <files>src/hooks/useTTS.ts</files>
  <action>
Modify `src/hooks/useTTS.ts` with the following changes:

1. Import SpeakerRole from types/debate.ts
2. Import useAudioStore from store/audioStore
3. Import getVoiceIdForRole from lib/voiceRegistry
4. Import { applyGlobalVolume } from components/AudioControls
5. Update UseStreamingTTSOptions interface:
   - Add speaker?: SpeakerRole parameter
   - Keep existing voiceId, provider, bufferSize, enabled parameters
6. Inside useStreamingTTS hook:
   - Get isEnabled from useAudioStore
   - Add logic to derive voice_id: if speaker is provided, use getVoiceIdForRole(speaker, provider), else use passed voiceId
   - Update generateAndQueueAudio to check isEnabled before generating TTS
   - Pass derived voice_id to generateTTS API call
7. In playAudio function (or where audio elements are created):
   - After creating HTMLAudioElement, call applyGlobalVolume(audioElement) to connect it to shared GainNode
   - This ensures all TTS audio respects global volume/mute controls
8. Update speakText function to accept speaker parameter and use voice registry

DO NOT:
- Add voice selection UI (that's in AudioControls component)
- Create GainNode instances (use shared one from AudioControls)
- Add voice parameter to every TTS call (only when speaker role is available)

Reference "Enhanced useStreamingTTS with Role-based Voice" example from 04-RESEARCH.md.
  </action>
  <verify>
```bash
npm run build
```
Build succeeds without TypeScript errors.
  </verify>
  <done>
useStreamingTTS hook enhanced with speaker parameter, uses getVoiceIdForRole for voice selection, checks isEnabled from audioStore, connects all audio elements to shared GainNode via applyGlobalVolume.
  </done>
</task>

<task type="auto">
  <name>Task 2: Integrate TTS into StreamingTranscriptEntry component</name>
  <files>src/components/StreamingTranscriptEntry.tsx</files>
  <action>
Modify `src/components/StreamingTranscriptEntry.tsx` to add TTS integration:

1. Import useStreamingTTS from hooks/useTTS
2. Use speaker prop (already passed to component as part of StreamingTranscriptEntry props)
3. Initialize useStreamingTTS hook:
   - Call with { speaker: speaker prop, enabled: true, bufferSize: 150 }
   - Destructure { queueText, flush } from hook
4. Add useEffect to stream text to TTS:
   - Call queueText with streaming text chunks as they arrive
   - On streaming completion or finalize, call flush() to play remaining text
   - Dependency array: [streaming text content]
5. Handle cleanup on unmount:
   - Call stop() from useStreamingTTS in useEffect cleanup
6. Ensure TTS only plays when streaming entry is active (not after finalization)

DO NOT:
- Add separate audio controls per entry (use global AudioControls)
- Access debateStore for speaker (speaker is already passed as prop)
- Create new audio elements (use shared AudioContext from AudioControls)
- Auto-play TTS on entry mount (respect global isEnabled setting)

Reference existing StreamingTranscriptEntry implementation for text streaming patterns.
  </action>
  <verify>
```bash
npm run build
```
Build succeeds without TypeScript errors.
  </verify>
  <done>
StreamingTranscriptEntry integrated with useStreamingTTS, queues text to TTS as it streams, flushes on completion, uses speaker prop (already passed to component) for voice selection.
  </done>
</task>

<task type="auto">
  <name>Task 3: Add AudioControls component to DebateDashboard</name>
  <files>src/components/DebateDashboard.tsx</files>
  <action>
Modify `src/components/DebateDashboard.tsx` to add AudioControls:

1. Import AudioControls from components/AudioControls
2. Add AudioControls component to dashboard layout:
   - Place in a visible location (e.g., top of dashboard, next to timer, or in a sidebar)
   - Ensure it doesn't interfere with debate flow visualization
   - Style consistently with existing dashboard elements (using Tailwind)
3. Ensure AudioControls renders on all debate states:
   - idle: Show controls (audio can be configured before starting)
   - active: Show controls (live audio adjustment)
   - paused: Show controls (audio can be paused along with debate)
   - completed: Show controls (can replay or replay with different settings)

DO NOT:
- Hide AudioControls when debate is idle (users should configure audio before starting)
- Duplicate audio controls (only one global instance)
- Move existing dashboard elements (add AudioControls in empty space)

Check existing DebateDashboard layout to find optimal placement (likely near timer or controls area).
  </action>
  <verify>
```bash
npm run build
```
Build succeeds without TypeScript errors.
  </verify>
  <done>
AudioControls component added to DebateDashboard, renders in visible location, accessible during all debate states, styled consistently with dashboard.
  </done>
</task>

</tasks>

<verification>
- useStreamingTTS accepts speaker parameter and uses voice registry
- StreamingTranscriptEntry queues text to TTS during streaming
- AudioControls visible in DebateDashboard
- All components compile without TypeScript errors
- Voice selection respects speaker role (PM, LO, MO, PW)
- Global audio enable/disable works via AudioControls
</verification>

<success_criteria>
Build succeeds, TTS plays with distinct voices per speaker role during streaming, AudioControls visible in dashboard, volume/speed/mute controls functional.
</success_criteria>

<output>
After completion, create `.planning/phases/04-audio-enhancement/04-03-SUMMARY.md`
</output>
